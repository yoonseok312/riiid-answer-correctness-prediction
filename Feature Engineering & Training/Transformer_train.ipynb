{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_train.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhVjSyXENSIO"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o34BI8_GNYjg"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from pickle import dump, load\n",
        "import gc"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf5LpnLNNbDd",
        "outputId": "7189998e-0fb2-4d1f-f5e6-67259a501579"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaGvW83jNfnb"
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "WIN_SIZE = 100"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgONz4U2Nh4l"
      },
      "source": [
        "def read_feather(file_name = \"train.feather\"):\n",
        "    data = pd.read_feather(file_name)\n",
        "    return data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHi4Ozk1Nkhm"
      },
      "source": [
        "user_dict = load(open('/content/drive/MyDrive/transformer_train/user_dict.pkl', 'rb'))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M9MQiMyNniR"
      },
      "source": [
        "tdf = read_feather('/content/drive/MyDrive/transformer_train/all_train_dat_plus.feather')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYfGSlSeNpie",
        "outputId": "ff81659e-b121-4d14-83fc-657690537a2c"
      },
      "source": [
        "tdf.numlect = tdf.numlect.astype(np.uint8)\n",
        "tdf.task_container_id[tdf.task_container_id > 2000] = 2000"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spaZaiKRNr4e"
      },
      "source": [
        "tdf.drop(columns = ['timestamp', 'user_id'], inplace = True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK0RUDQFNtls"
      },
      "source": [
        "def rolling_window(a, w):\n",
        "    s0, s1 = a.strides\n",
        "    m, n = a.shape\n",
        "    return np.lib.stride_tricks.as_strided(a, \n",
        "                                           shape=(m-w+1, w, n), \n",
        "                                           strides=(s0, s0, s1))\n",
        "\n",
        "def make_time_series(x, windows_size, pad_size=0):\n",
        "    x = np.pad(x, [[ windows_size-pad_size-1, 0], [0, 0]], constant_values=0)\n",
        "    x = rolling_window(x, windows_size)\n",
        "    return list(x)\n",
        "\n",
        "def shift_answer(df):\n",
        "    # We add one to the column in order to have zeros as padding values\n",
        "    # Start Of Sentence (SOS) token will be 3. \n",
        "    df['answered_correctly'] = df['answered_correctly'].shift(fill_value=2)+1\n",
        "    return df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xanpsLBNwsX"
      },
      "source": [
        "def dat_generator(df, user_dict, for_train = True, val_p1 = None, val_p2 = None, win_size = 128, batch_size = 256):\n",
        "    pos_to_uid = list(user_dict.keys())\n",
        "    pos_to_uid.sort()\n",
        "    if val_p2 is None: val_p2 = int(len(user_dict) * 0.9)\n",
        "    if val_p1 is None: val_p1 = int(val_p2 * 0.5)\n",
        "    if for_train:\n",
        "        remain_uid = list(range(val_p2))\n",
        "        rem_uid = None\n",
        "        use_dat = None\n",
        "        rem_uidx = None\n",
        "        while True:\n",
        "            X = []\n",
        "            y = []\n",
        "            remain_batch = batch_size\n",
        "            if rem_uid is not None: \n",
        "                if uid < pos_to_uid[val_p1]: utotal_dat = min(3000, len(user_dict[rem_uid]))\n",
        "                else: utotal_dat = min(3000, int(len(user_dict[rem_uid])*0.8))\n",
        "                u_dat = utotal_dat - use_dat\n",
        "                if u_dat <= remain_batch:\n",
        "                    y.extend(df.answered_correctly[user_dict[rem_uid][use_dat]:user_dict[rem_uid][utotal_dat-1]+1])\n",
        "                    t_use_dat = max(0, use_dat - win_size + 1)\n",
        "                    t_use = max(0, t_use_dat - 1)\n",
        "                    pad_size = use_dat\n",
        "                    if t_use_dat != 0: pad_size = win_size - 1\n",
        "                    udf = df[user_dict[rem_uid][t_use]:user_dict[rem_uid][utotal_dat-1]+1].copy()\n",
        "                    udf = shift_answer(udf)\n",
        "                    if t_use_dat != 0: udf = udf[1:].copy()\n",
        "                    X.extend(make_time_series(udf, win_size, pad_size = pad_size))\n",
        "                    remain_batch -= u_dat\n",
        "                    remain_uid.pop(rem_uidx)\n",
        "                    rem_uid = None\n",
        "                    rem_uidx = None\n",
        "                    use_dat = None\n",
        "                else:\n",
        "                    y.extend(df.answered_correctly[user_dict[rem_uid][use_dat]:user_dict[rem_uid][use_dat+remain_batch]])\n",
        "                    t_use_dat = max(0, use_dat - win_size + 1)\n",
        "                    t_use = max(0, t_use_dat - 1)\n",
        "                    pad_size = use_dat\n",
        "                    if t_use_dat != 0: pad_size = win_size - 1\n",
        "                    udf = df[user_dict[rem_uid][t_use]:user_dict[rem_uid][use_dat+remain_batch]].copy()\n",
        "                    udf = shift_answer(udf)\n",
        "                    if t_use_dat != 0: udf = udf[1:].copy()\n",
        "                    X.extend(make_time_series(udf, win_size, pad_size))\n",
        "                    use_dat += remain_batch\n",
        "                    remain_batch = 0\n",
        "            while remain_batch > 0:\n",
        "                if len(remain_uid)==0: remain_uid = list(range(val_p2))\n",
        "                uidx = np.random.choice(len(remain_uid), 1)[0]\n",
        "                uid = pos_to_uid[remain_uid[uidx]]\n",
        "                u_dat = min(3000, len(user_dict[uid]))\n",
        "                if u_dat < 20:\n",
        "                    remain_uid.pop(uidx)\n",
        "                    continue\n",
        "                if uid > pos_to_uid[val_p1]: u_dat = min(3000, int(len(user_dict[uid])*0.8))\n",
        "                if u_dat <= remain_batch:\n",
        "                    y.extend(df.answered_correctly[user_dict[uid][0]:user_dict[uid][u_dat-1]+1])\n",
        "                    udf = df[user_dict[uid][0]:user_dict[uid][u_dat-1]+1].copy()\n",
        "                    udf = shift_answer(udf)\n",
        "                    X.extend(make_time_series(udf, win_size))\n",
        "                    remain_batch -= u_dat\n",
        "                    remain_uid.pop(uidx)\n",
        "                else:\n",
        "                    y.extend(df.answered_correctly[user_dict[uid][0]:user_dict[uid][remain_batch]])\n",
        "                    udf = df[user_dict[uid][0]:user_dict[uid][remain_batch]].copy()\n",
        "                    udf = shift_answer(udf)\n",
        "                    X.extend(make_time_series(udf, win_size))\n",
        "                    rem_uid = uid\n",
        "                    rem_uidx = uidx\n",
        "                    use_dat = remain_batch\n",
        "                    remain_batch = 0\n",
        "            yield np.asarray(X).astype(np.float32), np.asarray(y).astype(np.float32)\n",
        "    else:\n",
        "        remain_uid = []\n",
        "        rem_uid = None\n",
        "        use_dat = None\n",
        "        rem_uidx = None\n",
        "        while True:\n",
        "            X = []\n",
        "            y = []\n",
        "            if len(remain_uid) == 0: remain_uid = list(range(val_p1, len(user_dict)))\n",
        "            uidx = np.random.choice([0, len(remain_uid) - 1], 1)[0]\n",
        "            uid = pos_to_uid[remain_uid[uidx]]\n",
        "            if uid > pos_to_uid[val_p2]:\n",
        "                u_dat = len(user_dict[uid])\n",
        "                start_token = - u_dat\n",
        "                end_token = -1\n",
        "                if u_dat > BATCH_SIZE: end_token = -u_dat + BATCH_SIZE\n",
        "            else:\n",
        "                if len(user_dict[uid]) < 10:\n",
        "                    remain_uid.pop(uidx)\n",
        "                    continue \n",
        "                u_dat = int(len(user_dict[uid])*0.2)\n",
        "                start_token = - u_dat - 1\n",
        "                end_token = -1\n",
        "                if u_dat > BATCH_SIZE: end_token = -u_dat + BATCH_SIZE\n",
        "            y.extend(df.answered_correctly[user_dict[uid][-u_dat]:user_dict[uid][end_token]+1])\n",
        "            udf = df[user_dict[uid][start_token]:user_dict[uid][end_token]+1].copy()\n",
        "            udf = shift_answer(udf)\n",
        "            if udf.shape[0] != len(y): udf = udf[1:].copy()\n",
        "            X.extend(make_time_series(udf, win_size))\n",
        "            remain_uid.pop(uidx)\n",
        "            yield np.asarray(X).astype(np.float32), np.asarray(y).astype(np.float32)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKOGH6_5Nzib"
      },
      "source": [
        "class MultiHeadAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8, **kwargs):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if self.embed_dim % self.num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {self.embed_dim} should be divisible by number of heads = {self.num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = self.embed_dim // self.num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "    \n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        cfg.update({\n",
        "            'embed_dim': self.embed_dim,\n",
        "            'num_heads': self.num_heads,\n",
        "        })\n",
        "        return cfg\n",
        "\n",
        "    def attention(self, query, key, value, mask):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        if mask is not None:\n",
        "            scaled_score += (mask * -1e9)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, q , k ,v, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "        print(\"batch size\", batch_size)\n",
        "        query = self.query_dense(q)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(k)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(v)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(query, batch_size)  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(key, batch_size)  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(value, batch_size)  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value, mask)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(concat_attention)  # (batch_size, seq_len, embed_dim)\n",
        "        return output # can return weights\n",
        "\n",
        "\"\"\"\n",
        "Encoder block as a layer\n",
        "\"\"\"\n",
        "\n",
        "class EncoderBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim = None, rate=0.1, **kwargs):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.ff_dim = ff_dim\n",
        "        self.rate = rate\n",
        "        self.att = MultiHeadAttention(self.embed_dim, self.num_heads)\n",
        "        if self.ff_dim is None: self.ff_dim = 2*self.embed_dim\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [layers.Dense(self.ff_dim, activation=\"relu\"), layers.Dense(self.embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(self.rate)\n",
        "        self.dropout2 = layers.Dropout(self.rate)\n",
        "        \n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        cfg.update({\n",
        "            'embed_dim': self.embed_dim,\n",
        "            'num_heads': self.num_heads,\n",
        "            'ff_dim': self.ff_dim,\n",
        "            'rate': self.rate\n",
        "        })\n",
        "        return cfg\n",
        "\n",
        "    def call(self, x, y, padding_mask, training):\n",
        "        attn_output = self.att(x, y, y, padding_mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "\"\"\"\n",
        "Decoder block as a layer\n",
        "\"\"\"\n",
        "\n",
        "class DecoderBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim = None, rate = 0.1, **kwargs):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.ff_dim = ff_dim\n",
        "        self.rate = rate\n",
        "        self.att1 = MultiHeadAttention(self.embed_dim, self.num_heads)\n",
        "        self.att2 = MultiHeadAttention(self.embed_dim, self.num_heads)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [layers.Dense(self.ff_dim, activation=\"relu\"), layers.Dense(self.embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(self.rate)\n",
        "        self.dropout2 = layers.Dropout(self.rate)\n",
        "        self.dropout3 = layers.Dropout(self.rate)\n",
        "        \n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        cfg.update({\n",
        "            'embed_dim': self.embed_dim,\n",
        "            'num_heads': self.num_heads,\n",
        "            'ff_dim': self.ff_dim,\n",
        "            'rate': self.rate\n",
        "        })\n",
        "        return cfg\n",
        "    \n",
        "    def call(self, x, enc_output, look_ahead_mask, padding_mask, training):\n",
        "        attn1 = self.att1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training = training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "        \n",
        "        attn2 = self.att2(out1, enc_output, enc_output, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training = training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "        \n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training = training)\n",
        "        return self.layernorm3(ffn_output + out2)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5ZHgElGN2aE"
      },
      "source": [
        "def create_padding_mask(seqs):\n",
        "    mask = tf.cast(tf.reduce_all(tf.math.equal(seqs, 0), axis=-1), tf.float32)\n",
        "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask  # (seq_len, seq_len)\n",
        "\n",
        "def get_angles(pos, i, embed_dim):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(embed_dim))\n",
        "    return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, embed_dim):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(embed_dim)[np.newaxis, :],\n",
        "                            embed_dim)\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCyOple1N5Yf"
      },
      "source": [
        "def custom_transformer_model(feature_dim, window_size, q_size=13524, embed_dim = 256, num_heads = 16, dense_dim = 1024):\n",
        "    inputs = layers.Input(shape=(window_size, feature_dim), name = \"enc_input\")\n",
        "    min_delta = inputs[...,0]\n",
        "    day_delta = inputs[...,1]\n",
        "    month_delta = inputs[...,2]\n",
        "    cid = inputs[...,3]\n",
        "    tid = inputs[...,4]\n",
        "    prior_elapsed = inputs[...,5]\n",
        "    prior_explained = inputs[...,6]\n",
        "    is_with = inputs[...,7]\n",
        "    num_lect = inputs[...,-1,8]\n",
        "    lec_type = inputs[...,-1,9:13]\n",
        "    lec_h_past = inputs[...,-1,13]\n",
        "    c_part = inputs[...,14:23]\n",
        "    tag1 = inputs[...,23]\n",
        "    tag2 = inputs[...,24]\n",
        "    tag3 = inputs[...,25]\n",
        "    tag4 = inputs[...,26]\n",
        "    tag5 = inputs[...,27]\n",
        "    tag6 = inputs[...,28]\n",
        "    prev_answered_correct = inputs[...,29]\n",
        "    \n",
        "    #====Excercise====\n",
        "    min_delta = layers.Embedding(input_dim=1443, output_dim=embed_dim//8, input_length=window_size,\n",
        "                                 embeddings_initializer = 'glorot_uniform')(min_delta)\n",
        "    day_delta = layers.Embedding(input_dim=33, output_dim=embed_dim//16, input_length=window_size,\n",
        "                                 embeddings_initializer = 'glorot_uniform')(day_delta)\n",
        "    month_delta = layers.Embedding(input_dim=9, output_dim=embed_dim//16, input_length=window_size,\n",
        "                                   embeddings_initializer = 'glorot_uniform')(month_delta)\n",
        "    cid = layers.Embedding(input_dim=q_size, output_dim=embed_dim, input_length=window_size,\n",
        "                           embeddings_initializer = 'glorot_uniform')(cid)\n",
        "    tid = layers.Embedding(input_dim=2001, output_dim=embed_dim//16, input_length=window_size,\n",
        "                           embeddings_initializer = 'glorot_uniform')(tid)\n",
        "    is_with = layers.Embedding(input_dim=3, output_dim=2, input_length=window_size,\n",
        "                               embeddings_initializer = 'glorot_uniform')(is_with)\n",
        "    c_part = layers.Dense(embed_dim//4, activation = 'relu', use_bias=False)(c_part)\n",
        "#     tag_emb = layers.Embedding(input_dim=189, output_dim=embed_dim//4)\n",
        "    tag1 = layers.Embedding(input_dim=189, output_dim=embed_dim//8, input_length=window_size,\n",
        "                            embeddings_initializer = 'glorot_uniform')(tag1)\n",
        "    tag2 = layers.Embedding(input_dim=179, output_dim=embed_dim//8, input_length=window_size,\n",
        "                            embeddings_initializer = 'glorot_uniform')(tag2)\n",
        "    tag3 = layers.Embedding(input_dim=162, output_dim=embed_dim//8, input_length=window_size,\n",
        "                            embeddings_initializer = 'glorot_uniform')(tag3)\n",
        "#     tag4 = tag_emb(tag4)\n",
        "#     tag5 = tag_emb(tag5)\n",
        "#     tag6 = tag_emb(tag6)\n",
        "    enc_ex = layers.Concatenate()([min_delta, day_delta, month_delta, tid, c_part,\n",
        "                                 tag1, tag2, tag3, is_with]) #tag4, tag5, tag6\n",
        "    enc_ex = layers.Dense(embed_dim, activation = 'relu')(enc_ex)\n",
        "    \n",
        "    #====Lecture====\n",
        "    num_lect = layers.Embedding(input_dim=160, output_dim=embed_dim//16,\n",
        "                                embeddings_initializer = 'glorot_uniform')(num_lect)\n",
        "    lec_type = layers.Dense(embed_dim//8, activation = 'relu', use_bias=False)(lec_type)\n",
        "    lec_h_past = layers.Embedding(input_dim=724, output_dim=embed_dim//8,\n",
        "                                  embeddings_initializer = 'glorot_uniform')(lec_h_past)\n",
        "    enc_lec = layers.Concatenate()([num_lect, lec_type, lec_h_past])\n",
        "    enc_lec = layers.Dense(embed_dim//2, activation = 'relu')(enc_lec)\n",
        "    enc_lec = layers.Dropout(0.1)(enc_lec)\n",
        "\n",
        "    #====Response====\n",
        "    prev_answered_correct = layers.Embedding(input_dim=4, output_dim=embed_dim, input_length=window_size,\n",
        "                                             embeddings_initializer = 'glorot_uniform')(prev_answered_correct)\n",
        "    prior_elapsed = layers.Embedding(input_dim=302, output_dim=embed_dim//4, input_length=window_size,\n",
        "                                     embeddings_initializer = 'glorot_uniform')(prior_elapsed)\n",
        "    prior_explained = layers.Embedding(input_dim=3, output_dim=embed_dim//4, input_length=window_size,\n",
        "                                       embeddings_initializer = 'glorot_uniform')(prior_explained)\n",
        "    prior_inter = layers.Concatenate()([prior_elapsed, prior_explained])\n",
        "    prior_inter = layers.Dense(embed_dim, activation = 'relu')(prior_inter)\n",
        "    \n",
        "    #====Mask====\n",
        "    padding_mask = create_padding_mask(inputs)\n",
        "    look_ahead_mask = create_look_ahead_mask(window_size)\n",
        "    dec_combined_mask = tf.maximum(padding_mask, look_ahead_mask)\n",
        "    pos_enc = positional_encoding(window_size, embed_dim)\n",
        "    \n",
        "    #++++Model++++\n",
        "    e_enc_input = layers.Add()([cid, pos_enc, enc_ex])\n",
        "    dec_input = layers.Add()([prev_answered_correct, pos_enc, prior_inter])\n",
        "    \n",
        "    x1 = EncoderBlock(embed_dim, num_heads, ff_dim = dense_dim)(e_enc_input, e_enc_input, padding_mask)\n",
        "    x1 = EncoderBlock(embed_dim, num_heads, ff_dim = dense_dim)(x1, x1, padding_mask)\n",
        "    x1 = layers.Add()([e_enc_input, x1])\n",
        "    x3 = DecoderBlock(embed_dim, num_heads, ff_dim = dense_dim)(dec_input, x1,\n",
        "                                                                dec_combined_mask, padding_mask)\n",
        "    x3 = DecoderBlock(embed_dim, num_heads, ff_dim = dense_dim)(x3, x1,\n",
        "                                                                dec_combined_mask, padding_mask)\n",
        "    x = x3[:, -1, :]\n",
        "    x = layers.Concatenate()([x, enc_lec])\n",
        "    x = layers.Dense(embed_dim, activation=\"relu\")(x)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\",\n",
        "                           kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),\n",
        "                           name = \"output\")(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8daHJ6ZN8tu"
      },
      "source": [
        "val_step = int(tdf.shape[0]*0.2 / BATCH_SIZE)\n",
        "train_step = int(tdf.shape[0]*0.8 / BATCH_SIZE)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlFMV36rOBR1",
        "outputId": "3bc36649-c12d-4fd3-f3c7-5b7016b4416e"
      },
      "source": [
        "model = custom_transformer_model(30, WIN_SIZE, embed_dim = 128, dense_dim = 512, num_heads=8)\n",
        "model.summary()\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer='adam',\n",
        "              run_eagerly=True, metrics=['AUC', 'acc'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch size Tensor(\"encoder_block/multi_head_attention/strided_slice:0\", shape=(), dtype=int32)\n",
            "batch size Tensor(\"encoder_block_1/multi_head_attention_1/strided_slice:0\", shape=(), dtype=int32)\n",
            "batch size Tensor(\"decoder_block/multi_head_attention_2/strided_slice:0\", shape=(), dtype=int32)\n",
            "batch size Tensor(\"decoder_block/multi_head_attention_3/strided_slice:0\", shape=(), dtype=int32)\n",
            "batch size Tensor(\"decoder_block_1/multi_head_attention_4/strided_slice:0\", shape=(), dtype=int32)\n",
            "batch size Tensor(\"decoder_block_1/multi_head_attention_5/strided_slice:0\", shape=(), dtype=int32)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "enc_input (InputLayer)          [(None, 100, 30)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (Slici (None, 100)          0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_1 (Sli (None, 100)          0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_2 (Sli (None, 100)          0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_4 (Sli (None, 100)          0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_11 (Sl (None, 100, 9)       0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_12 (Sl (None, 100)          0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_13 (Sl (None, 100)          0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_14 (Sl (None, 100)          0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_7 (Sli (None, 100)          0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 100, 16)      23088       tf.__operators__.getitem[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 100, 8)       264         tf.__operators__.getitem_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 100, 8)       72          tf.__operators__.getitem_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 100, 8)       16008       tf.__operators__.getitem_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100, 32)      288         tf.__operators__.getitem_11[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 100, 16)      3024        tf.__operators__.getitem_12[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 100, 16)      2864        tf.__operators__.getitem_13[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 100, 16)      2592        tf.__operators__.getitem_14[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 100, 2)       6           tf.__operators__.getitem_7[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.equal (TFOpLambda)      (None, 100, 30)      0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_3 (Sli (None, 100)          0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 100, 122)     0           embedding[0][0]                  \n",
            "                                                                 embedding_1[0][0]                \n",
            "                                                                 embedding_2[0][0]                \n",
            "                                                                 embedding_4[0][0]                \n",
            "                                                                 dense[0][0]                      \n",
            "                                                                 embedding_6[0][0]                \n",
            "                                                                 embedding_7[0][0]                \n",
            "                                                                 embedding_8[0][0]                \n",
            "                                                                 embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_all (TFOpLambda) (None, 100)          0           tf.math.equal[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_5 (Sli (None, 100)          0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_6 (Sli (None, 100)          0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 100, 128)     1731072     tf.__operators__.getitem_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100, 128)     15744       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf.cast (TFOpLambda)            (None, 100)          0           tf.math.reduce_all[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "embedding_12 (Embedding)        (None, 100, 32)      9664        tf.__operators__.getitem_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "embedding_13 (Embedding)        (None, 100, 32)      96          tf.__operators__.getitem_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 100, 128)     0           embedding_3[0][0]                \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_19 (Sl (None, 1, 1, 100)    0           tf.cast[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_18 (Sl (None, 100)          0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 100, 64)      0           embedding_12[0][0]               \n",
            "                                                                 embedding_13[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_block (EncoderBlock)    (None, 100, 128)     198272      add[0][0]                        \n",
            "                                                                 add[0][0]                        \n",
            "                                                                 tf.__operators__.getitem_19[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, 100, 128)     512         tf.__operators__.getitem_18[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 100, 128)     8320        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "encoder_block_1 (EncoderBlock)  (None, 100, 128)     198272      encoder_block[0][0]              \n",
            "                                                                 encoder_block[0][0]              \n",
            "                                                                 tf.__operators__.getitem_19[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_8 (Sli (None,)              0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_9 (Sli (None, 4)            0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_10 (Sl (None,)              0           enc_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 100, 128)     0           embedding_11[0][0]               \n",
            "                                                                 dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 100, 128)     0           add[0][0]                        \n",
            "                                                                 encoder_block_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.maximum (TFOpLambda)    (None, 1, 100, 100)  0           tf.__operators__.getitem_19[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 8)            1280        tf.__operators__.getitem_8[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 16)           64          tf.__operators__.getitem_9[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "embedding_10 (Embedding)        (None, 16)           11584       tf.__operators__.getitem_10[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "decoder_block (DecoderBlock)    (None, 100, 128)     264576      add_1[0][0]                      \n",
            "                                                                 add_2[0][0]                      \n",
            "                                                                 tf.math.maximum[0][0]            \n",
            "                                                                 tf.__operators__.getitem_19[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 40)           0           embedding_9[0][0]                \n",
            "                                                                 dense_2[0][0]                    \n",
            "                                                                 embedding_10[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_block_1 (DecoderBlock)  (None, 100, 128)     264576      decoder_block[0][0]              \n",
            "                                                                 add_2[0][0]                      \n",
            "                                                                 tf.math.maximum[0][0]            \n",
            "                                                                 tf.__operators__.getitem_19[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 64)           2624        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_20 (Sl (None, 128)          0           decoder_block_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 64)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 192)          0           tf.__operators__.getitem_20[0][0]\n",
            "                                                                 dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_37 (Dense)                (None, 128)          24704       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 128)          0           dense_37[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            129         dropout_11[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 2,779,695\n",
            "Trainable params: 2,779,695\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT0WfpEaOF7a"
      },
      "source": [
        "model_name = \"SSAKT_2\"\n",
        "model_folder = \"ckp_dir/\" + model_name\n",
        "tblogs = \"tbl_dir\"\n",
        "if not os.path.exists(model_folder):\n",
        "    os.makedirs(model_folder)\n",
        "if not os.path.exists(tblogs):\n",
        "    os.mkdir(tblogs)\n",
        "\n",
        "# model_checkpoints = ModelCheckpoint('{}/{}'.format(model_folder, model_name)+'-{epoch:02d}_{loss:.4f}_{auc:.4f}_{val_loss:.4f}_{val_auc:.4f}.h5', save_best_only=True, monitor='val_auc', mode='max')\n",
        "model_checkpoints = ModelCheckpoint('{}/{}'.format(model_folder, model_name)+'.{epoch:02d}_{loss:.4f}_{auc:.4f}_{val_loss:.4f}_{val_auc:.4f}.h5')\n",
        "lr_auto = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 7, mode = \"min\", min_delta = 0.0001, min_lr = 0.0000001, verbose = 1)\n",
        "log_dir = \"{}/{}-{}\".format(tblogs, model_name, time.time())\n",
        "tensorboard = TensorBoard(log_dir=log_dir)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpPnHz-ZOGbC"
      },
      "source": [
        "train_gen = dat_generator(tdf, user_dict, win_size = WIN_SIZE, batch_size=BATCH_SIZE)\n",
        "val_gen = dat_generator(tdf, user_dict, for_train = False, win_size = WIN_SIZE, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HIeSDD_EOIvI",
        "outputId": "b8f5113d-eacd-4aae-818e-fa8045c56eb3"
      },
      "source": [
        "model.fit(train_gen, epochs = 5, initial_epoch = 0,\n",
        "          callbacks=[model_checkpoints, lr_auto, tensorboard],\n",
        "          validation_data = val_gen, steps_per_epoch = train_step, validation_steps = val_step,\n",
        "          )#class_weight=class_weight"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "     1/155111 [..............................] - ETA: 68:16:58 - loss: 0.7120 - auc: 0.5034 - acc: 0.3906batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "     2/155111 [..............................] - ETA: 19:12:40 - loss: 0.7043 - auc: 0.4875 - acc: 0.4438batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "     3/155111 [..............................] - ETA: 24:29:09 - loss: 0.6955 - auc: 0.4862 - acc: 0.4806batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "     4/155111 [..............................] - ETA: 22:27:57 - loss: 0.6889 - auc: 0.4857 - acc: 0.5059batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "     5/155111 [..............................] - ETA: 21:34:11 - loss: 0.6827 - auc: 0.4893 - acc: 0.5256batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "     6/155111 [..............................] - ETA: 20:53:02 - loss: 0.6778 - auc: 0.4928 - acc: 0.5407batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "     7/155111 [..............................] - ETA: 20:23:06 - loss: 0.6765 - auc: 0.4915 - acc: 0.5500batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "     8/155111 [..............................] - ETA: 20:01:47 - loss: 0.6757 - auc: 0.4904 - acc: 0.5571batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "     9/155111 [..............................] - ETA: 19:44:49 - loss: 0.6745 - auc: 0.4898 - acc: 0.5635batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    10/155111 [..............................] - ETA: 19:32:54 - loss: 0.6729 - auc: 0.4885 - acc: 0.5700batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    11/155111 [..............................] - ETA: 19:23:36 - loss: 0.6715 - auc: 0.4877 - acc: 0.5755batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    12/155111 [..............................] - ETA: 19:16:07 - loss: 0.6700 - auc: 0.4868 - acc: 0.5808batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    13/155111 [..............................] - ETA: 19:10:16 - loss: 0.6686 - auc: 0.4862 - acc: 0.5854batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    14/155111 [..............................] - ETA: 19:05:47 - loss: 0.6671 - auc: 0.4859 - acc: 0.5899batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    15/155111 [..............................] - ETA: 19:01:45 - loss: 0.6657 - auc: 0.4856 - acc: 0.5939batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    16/155111 [..............................] - ETA: 18:58:34 - loss: 0.6645 - auc: 0.4854 - acc: 0.5975batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    17/155111 [..............................] - ETA: 18:56:04 - loss: 0.6634 - auc: 0.4852 - acc: 0.6006batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    18/155111 [..............................] - ETA: 18:54:15 - loss: 0.6624 - auc: 0.4852 - acc: 0.6035batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    19/155111 [..............................] - ETA: 18:51:38 - loss: 0.6616 - auc: 0.4849 - acc: 0.6060batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    20/155111 [..............................] - ETA: 18:48:50 - loss: 0.6612 - auc: 0.4844 - acc: 0.6079batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    21/155111 [..............................] - ETA: 18:46:32 - loss: 0.6607 - auc: 0.4840 - acc: 0.6098batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    22/155111 [..............................] - ETA: 18:45:24 - loss: 0.6602 - auc: 0.4837 - acc: 0.6116batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    23/155111 [..............................] - ETA: 18:44:01 - loss: 0.6597 - auc: 0.4834 - acc: 0.6133batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    24/155111 [..............................] - ETA: 18:42:20 - loss: 0.6593 - auc: 0.4833 - acc: 0.6147batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    25/155111 [..............................] - ETA: 18:40:08 - loss: 0.6591 - auc: 0.4835 - acc: 0.6158batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    26/155111 [..............................] - ETA: 18:39:27 - loss: 0.6589 - auc: 0.4838 - acc: 0.6167batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    27/155111 [..............................] - ETA: 18:38:43 - loss: 0.6588 - auc: 0.4844 - acc: 0.6175batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    28/155111 [..............................] - ETA: 18:37:16 - loss: 0.6587 - auc: 0.4847 - acc: 0.6182batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    29/155111 [..............................] - ETA: 18:35:31 - loss: 0.6585 - auc: 0.4848 - acc: 0.6191batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    30/155111 [..............................] - ETA: 18:35:20 - loss: 0.6584 - auc: 0.4846 - acc: 0.6201batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    31/155111 [..............................] - ETA: 18:34:29 - loss: 0.6582 - auc: 0.4844 - acc: 0.6211batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    32/155111 [..............................] - ETA: 18:34:03 - loss: 0.6580 - auc: 0.4843 - acc: 0.6220batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    33/155111 [..............................] - ETA: 18:32:39 - loss: 0.6578 - auc: 0.4842 - acc: 0.6229batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    34/155111 [..............................] - ETA: 18:32:03 - loss: 0.6577 - auc: 0.4841 - acc: 0.6236batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    35/155111 [..............................] - ETA: 18:31:12 - loss: 0.6575 - auc: 0.4841 - acc: 0.6243batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    36/155111 [..............................] - ETA: 18:31:04 - loss: 0.6574 - auc: 0.4841 - acc: 0.6251batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    37/155111 [..............................] - ETA: 18:30:22 - loss: 0.6572 - auc: 0.4840 - acc: 0.6257batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    38/155111 [..............................] - ETA: 18:29:16 - loss: 0.6571 - auc: 0.4840 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    39/155111 [..............................] - ETA: 18:28:09 - loss: 0.6570 - auc: 0.4839 - acc: 0.6268batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    40/155111 [..............................] - ETA: 18:27:19 - loss: 0.6569 - auc: 0.4839 - acc: 0.6274batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    41/155111 [..............................] - ETA: 18:26:20 - loss: 0.6567 - auc: 0.4839 - acc: 0.6280batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    42/155111 [..............................] - ETA: 18:25:43 - loss: 0.6566 - auc: 0.4840 - acc: 0.6286batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    43/155111 [..............................] - ETA: 18:25:10 - loss: 0.6564 - auc: 0.4840 - acc: 0.6292batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    44/155111 [..............................] - ETA: 18:24:36 - loss: 0.6562 - auc: 0.4841 - acc: 0.6297batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    45/155111 [..............................] - ETA: 18:24:02 - loss: 0.6561 - auc: 0.4841 - acc: 0.6302batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    46/155111 [..............................] - ETA: 18:23:35 - loss: 0.6561 - auc: 0.4840 - acc: 0.6306batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    47/155111 [..............................] - ETA: 18:22:54 - loss: 0.6560 - auc: 0.4840 - acc: 0.6309batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    48/155111 [..............................] - ETA: 18:22:28 - loss: 0.6559 - auc: 0.4839 - acc: 0.6313batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    49/155111 [..............................] - ETA: 18:22:05 - loss: 0.6559 - auc: 0.4839 - acc: 0.6316batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    50/155111 [..............................] - ETA: 18:21:30 - loss: 0.6559 - auc: 0.4839 - acc: 0.6318batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    51/155111 [..............................] - ETA: 18:21:21 - loss: 0.6559 - auc: 0.4839 - acc: 0.6321batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    52/155111 [..............................] - ETA: 18:21:01 - loss: 0.6559 - auc: 0.4839 - acc: 0.6323batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    53/155111 [..............................] - ETA: 18:20:50 - loss: 0.6559 - auc: 0.4840 - acc: 0.6325batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    54/155111 [..............................] - ETA: 18:20:26 - loss: 0.6559 - auc: 0.4842 - acc: 0.6326batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    55/155111 [..............................] - ETA: 18:20:09 - loss: 0.6559 - auc: 0.4844 - acc: 0.6327batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    56/155111 [..............................] - ETA: 18:19:40 - loss: 0.6560 - auc: 0.4848 - acc: 0.6327batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    57/155111 [..............................] - ETA: 18:19:45 - loss: 0.6560 - auc: 0.4854 - acc: 0.6326batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    58/155111 [..............................] - ETA: 18:19:33 - loss: 0.6561 - auc: 0.4860 - acc: 0.6325batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    59/155111 [..............................] - ETA: 18:19:14 - loss: 0.6562 - auc: 0.4866 - acc: 0.6324batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    60/155111 [..............................] - ETA: 18:18:49 - loss: 0.6563 - auc: 0.4871 - acc: 0.6321batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    61/155111 [..............................] - ETA: 18:18:36 - loss: 0.6564 - auc: 0.4875 - acc: 0.6319batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    62/155111 [..............................] - ETA: 18:18:21 - loss: 0.6565 - auc: 0.4879 - acc: 0.6316batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    63/155111 [..............................] - ETA: 18:18:07 - loss: 0.6566 - auc: 0.4882 - acc: 0.6313batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    64/155111 [..............................] - ETA: 18:17:55 - loss: 0.6568 - auc: 0.4885 - acc: 0.6310batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    65/155111 [..............................] - ETA: 18:18:06 - loss: 0.6569 - auc: 0.4887 - acc: 0.6307batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    66/155111 [..............................] - ETA: 18:17:48 - loss: 0.6570 - auc: 0.4890 - acc: 0.6305batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    67/155111 [..............................] - ETA: 18:17:24 - loss: 0.6571 - auc: 0.4893 - acc: 0.6302batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    68/155111 [..............................] - ETA: 18:17:13 - loss: 0.6572 - auc: 0.4896 - acc: 0.6299batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    69/155111 [..............................] - ETA: 18:17:16 - loss: 0.6573 - auc: 0.4899 - acc: 0.6296batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    70/155111 [..............................] - ETA: 18:17:24 - loss: 0.6574 - auc: 0.4901 - acc: 0.6294batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    71/155111 [..............................] - ETA: 18:17:21 - loss: 0.6576 - auc: 0.4904 - acc: 0.6291batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    72/155111 [..............................] - ETA: 18:17:12 - loss: 0.6577 - auc: 0.4907 - acc: 0.6288batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    73/155111 [..............................] - ETA: 18:16:58 - loss: 0.6578 - auc: 0.4910 - acc: 0.6286batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    74/155111 [..............................] - ETA: 18:16:54 - loss: 0.6579 - auc: 0.4913 - acc: 0.6283batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    75/155111 [..............................] - ETA: 18:16:57 - loss: 0.6580 - auc: 0.4915 - acc: 0.6281batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    76/155111 [..............................] - ETA: 18:16:47 - loss: 0.6581 - auc: 0.4918 - acc: 0.6279batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    77/155111 [..............................] - ETA: 18:16:31 - loss: 0.6582 - auc: 0.4920 - acc: 0.6278batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    78/155111 [..............................] - ETA: 18:16:28 - loss: 0.6582 - auc: 0.4923 - acc: 0.6276batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    79/155111 [..............................] - ETA: 18:16:32 - loss: 0.6583 - auc: 0.4925 - acc: 0.6275batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    80/155111 [..............................] - ETA: 18:16:28 - loss: 0.6583 - auc: 0.4928 - acc: 0.6274batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    81/155111 [..............................] - ETA: 18:17:03 - loss: 0.6583 - auc: 0.4930 - acc: 0.6273batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    82/155111 [..............................] - ETA: 18:17:09 - loss: 0.6584 - auc: 0.4932 - acc: 0.6272batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    83/155111 [..............................] - ETA: 18:17:07 - loss: 0.6584 - auc: 0.4934 - acc: 0.6270batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    84/155111 [..............................] - ETA: 18:17:14 - loss: 0.6585 - auc: 0.4936 - acc: 0.6269batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    85/155111 [..............................] - ETA: 18:17:11 - loss: 0.6585 - auc: 0.4938 - acc: 0.6268batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    86/155111 [..............................] - ETA: 18:17:03 - loss: 0.6586 - auc: 0.4941 - acc: 0.6267batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    87/155111 [..............................] - ETA: 18:17:07 - loss: 0.6586 - auc: 0.4943 - acc: 0.6266batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    88/155111 [..............................] - ETA: 18:16:57 - loss: 0.6587 - auc: 0.4945 - acc: 0.6265batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    89/155111 [..............................] - ETA: 18:16:51 - loss: 0.6587 - auc: 0.4947 - acc: 0.6264batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    90/155111 [..............................] - ETA: 18:16:34 - loss: 0.6587 - auc: 0.4949 - acc: 0.6264batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    91/155111 [..............................] - ETA: 18:16:27 - loss: 0.6588 - auc: 0.4951 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    92/155111 [..............................] - ETA: 18:16:18 - loss: 0.6588 - auc: 0.4954 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    93/155111 [..............................] - ETA: 18:16:22 - loss: 0.6588 - auc: 0.4956 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    94/155111 [..............................] - ETA: 18:16:06 - loss: 0.6588 - auc: 0.4958 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    95/155111 [..............................] - ETA: 18:15:53 - loss: 0.6588 - auc: 0.4961 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    96/155111 [..............................] - ETA: 18:15:42 - loss: 0.6588 - auc: 0.4963 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    97/155111 [..............................] - ETA: 18:15:52 - loss: 0.6588 - auc: 0.4965 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    98/155111 [..............................] - ETA: 18:16:08 - loss: 0.6588 - auc: 0.4967 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "    99/155111 [..............................] - ETA: 18:16:05 - loss: 0.6588 - auc: 0.4969 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   100/155111 [..............................] - ETA: 18:16:04 - loss: 0.6588 - auc: 0.4972 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   101/155111 [..............................] - ETA: 18:15:57 - loss: 0.6588 - auc: 0.4974 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   102/155111 [..............................] - ETA: 18:15:50 - loss: 0.6588 - auc: 0.4976 - acc: 0.6261batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   103/155111 [..............................] - ETA: 18:15:56 - loss: 0.6588 - auc: 0.4978 - acc: 0.6261batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   104/155111 [..............................] - ETA: 18:16:06 - loss: 0.6588 - auc: 0.4980 - acc: 0.6261batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   105/155111 [..............................] - ETA: 18:16:06 - loss: 0.6588 - auc: 0.4982 - acc: 0.6261batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   106/155111 [..............................] - ETA: 18:16:01 - loss: 0.6587 - auc: 0.4984 - acc: 0.6261batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   107/155111 [..............................] - ETA: 18:15:53 - loss: 0.6587 - auc: 0.4987 - acc: 0.6261batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   108/155111 [..............................] - ETA: 18:15:53 - loss: 0.6587 - auc: 0.4989 - acc: 0.6261batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   109/155111 [..............................] - ETA: 18:15:54 - loss: 0.6587 - auc: 0.4991 - acc: 0.6261batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   110/155111 [..............................] - ETA: 18:15:46 - loss: 0.6587 - auc: 0.4993 - acc: 0.6261batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   111/155111 [..............................] - ETA: 18:15:39 - loss: 0.6587 - auc: 0.4994 - acc: 0.6261batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   112/155111 [..............................] - ETA: 18:15:47 - loss: 0.6587 - auc: 0.4996 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   113/155111 [..............................] - ETA: 18:15:39 - loss: 0.6586 - auc: 0.4998 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   114/155111 [..............................] - ETA: 18:15:30 - loss: 0.6586 - auc: 0.5000 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   115/155111 [..............................] - ETA: 18:15:27 - loss: 0.6586 - auc: 0.5002 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   116/155111 [..............................] - ETA: 18:15:24 - loss: 0.6586 - auc: 0.5004 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   117/155111 [..............................] - ETA: 18:15:23 - loss: 0.6586 - auc: 0.5006 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   118/155111 [..............................] - ETA: 18:15:12 - loss: 0.6586 - auc: 0.5007 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   119/155111 [..............................] - ETA: 18:15:04 - loss: 0.6585 - auc: 0.5009 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   120/155111 [..............................] - ETA: 18:14:57 - loss: 0.6585 - auc: 0.5011 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   121/155111 [..............................] - ETA: 18:14:52 - loss: 0.6585 - auc: 0.5012 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   122/155111 [..............................] - ETA: 18:14:51 - loss: 0.6585 - auc: 0.5014 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   123/155111 [..............................] - ETA: 18:14:46 - loss: 0.6585 - auc: 0.5015 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   124/155111 [..............................] - ETA: 18:14:52 - loss: 0.6585 - auc: 0.5017 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   125/155111 [..............................] - ETA: 18:14:45 - loss: 0.6585 - auc: 0.5018 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   126/155111 [..............................] - ETA: 18:14:42 - loss: 0.6585 - auc: 0.5020 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   127/155111 [..............................] - ETA: 18:14:41 - loss: 0.6585 - auc: 0.5021 - acc: 0.6264batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   128/155111 [..............................] - ETA: 18:14:44 - loss: 0.6585 - auc: 0.5022 - acc: 0.6264batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   129/155111 [..............................] - ETA: 18:14:46 - loss: 0.6584 - auc: 0.5024 - acc: 0.6264batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   130/155111 [..............................] - ETA: 18:14:41 - loss: 0.6584 - auc: 0.5025 - acc: 0.6264batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   131/155111 [..............................] - ETA: 18:14:33 - loss: 0.6584 - auc: 0.5027 - acc: 0.6264batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   132/155111 [..............................] - ETA: 18:14:28 - loss: 0.6584 - auc: 0.5028 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   133/155111 [..............................] - ETA: 18:14:34 - loss: 0.6585 - auc: 0.5030 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   134/155111 [..............................] - ETA: 18:14:33 - loss: 0.6585 - auc: 0.5032 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   135/155111 [..............................] - ETA: 18:14:34 - loss: 0.6585 - auc: 0.5033 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   136/155111 [..............................] - ETA: 18:14:20 - loss: 0.6585 - auc: 0.5035 - acc: 0.6263batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   137/155111 [..............................] - ETA: 18:14:14 - loss: 0.6585 - auc: 0.5036 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   138/155111 [..............................] - ETA: 18:14:06 - loss: 0.6585 - auc: 0.5038 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   139/155111 [..............................] - ETA: 18:14:00 - loss: 0.6585 - auc: 0.5040 - acc: 0.6262batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   140/155111 [..............................] - ETA: 18:13:55 - loss: 0.6585 - auc: 0.5041 - acc: 0.6261batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   141/155111 [..............................] - ETA: 18:13:54 - loss: 0.6585 - auc: 0.5043 - acc: 0.6261batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "   142/155111 [..............................] - ETA: 18:13:58 - loss: 0.6586 - auc: 0.5045 - acc: 0.6260batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n",
            "batch size tf.Tensor(512, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a26bef76a196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(train_gen, epochs = 3, initial_epoch = 0,\n\u001b[1;32m      2\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_auto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m           )#class_weight=class_weight\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    803\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    797\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3415\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    755\u001b[0m       loss = self.compiled_loss(\n\u001b[1;32m    756\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \"\"\"\n\u001b[1;32m    496\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 497\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0m\u001b[1;32m    498\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     self._assert_valid_dtypes([\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    439\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1692\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1694\u001b[0;31m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1695\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5527\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   5528\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5529\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   5530\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5531\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaW0ibUvO2dt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}