{"cells":[{"metadata":{},"cell_type":"markdown","source":"# *DATA PREPARATION*"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport time\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport gc\nimport random\nfrom pickle import dump, load\nfrom trueskill import Rating, quality_1vs1, rate_1vs1\nimport math\nimport trueskill\npd.options.mode.chained_assignment = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DTYPES = {\n    'row_id': np.uint64,\n    'timestamp': np.int64,\n    'user_id': np.uint64,\n    'content_id': np.uint16,\n    'content_type_id': np.int8,\n    'task_container_id': np.uint16,\n    'user_answer': np.int8,\n    'answered_correctly': np.int8,\n    'prior_question_elapsed_time': np.float32,\n    'prior_question_had_explanation': 'boolean'\n}\n\nQUESTION_DTYPES = {\n    'question_id': np.uint16,\n    'bundle_id': np.uint16,\n    'correct_answer': np.int8,\n    'part': np.int8,\n    'tags': str\n}\n\nLECTURE_DTYPES = {\n    'lecture_id': np.uint16,\n    'tag': np.uint16,\n    'part': np.int8,\n    'type_of':str\n}\n\nT_MASK = {24: 0, 23: 1, 58: 2, 134: 3, 52: 4, 124: 5, 44: 6, 123: 7, 67: 8, 167: 9, 161: 10, 43: 11, 80: 12,\n          46: 13, 28: 14, 103: 15, 94: 16, 186: 17, 26: 18, 180: 19, 50: 20, 182: 21, 31: 22, 6: 23, 15: 24,\n          11: 25, 108: 26, 47: 27, 76: 28, 165: 29, 174: 30, 48: 31, 152: 32, 132: 33, 170: 34, 49: 35,\n          181: 36, 159: 37, 145: 38, 73: 39, 64: 40, 1: 41, 7: 42, 16: 43, 57: 44, 21: 45, 95: 46, 72: 47,\n          91: 48, 125: 49, 157: 50, 96: 51, 156: 52, 53: 53, 55: 54, 45: 55, 4: 56, 133: 57, 136: 58, 75: 59,\n          39: 60, 89: 61, 65: 62, 117: 63, 173: 64, 83: 65, 8: 66, 166: 67, 25: 68, 168: 69, 79: 70, 3: 71,\n          97: 72, 60: 73, 128: 74, 179: 75, 14: 76, 151: 77, 164: 78, 112: 79, 116: 80, 42: 81, 22: 82, 0: 83,\n          127: 84, 160: 85, 147: 86, 19: 87, 32: 88, 183: 89, 12: 90, 9: 91, 86: 92, 109: 93, 175: 94, 10: 95,\n          115: 96, 78: 97, 171: 98, 148: 99, 113: 100, 27: 101, 35: 102, 169: 103, 92: 104, 122: 105, 54: 106,\n          114: 107, 18: 108, 17: 109, 56: 110, 107: 111, 90: 112, 163: 113, 126: 114, 29: 115, 66: 116,\n          106: 117, 135: 118, 2: 119, 87: 120, 138: 121, 71: 122, 100: 123, 41: 124, 30: 125, 154: 126,\n          102: 127, 84: 128, 81: 129, 37: 130, 146: 131, 185: 132, 155: 133, 176: 134, 143: 135, 121: 136,\n          85: 137, 162: 138, 184: 139, 104: 140, 38: 141, 140: 142, 82: 143, 120: 144, 20: 145, 88: 146,\n          141: 147, 119: 148, 139: 149, 150: 150, 98: 151, 62: 152, 33: 153, 144: 154, 158: 155, 74: 156,\n          13: 157, 61: 158, 110: 159, 69: 160, 137: 161, 111: 162, 34: 163, 118: 164, 153: 165, 129: 166,\n          178: 167, 105: 168, 177: 169, 36: 170, 172: 171, 142: 172, 63: 173, 101: 174, 59: 175, 5: 176,\n          131: 177, 99: 178, 93: 179, 51: 180, 77: 181, 40: 182, 70: 183, 149: 184, 68: 185, 187: 186, 130: 187}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_csv(file_name = \"train.csv\", dtype = None, skiprows = None, nrows = None, usecols = None):\n    data = pd.read_csv(file_name, dtype=dtype, skiprows = skiprows, nrows = nrows, low_memory = True, header = 0, usecols = usecols)\n    return data\n\ndef read_feather(file_name = \"../input/feather-data/train.feather\"):\n    data = pd.read_feather(file_name)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Get ts_delta of train.csv, save to feather\ndef get_ts_delta():\n    df = read_feather()\n    df = df[df['content_type_id'] == 0]\n    tsdf = df['timestamp'].astype(np.int64)\n    del df\n    oidx = list(range(tsdf.shape[0]))\n    last = [oidx[-1]]\n    oidx = oidx[:-1]\n    last.extend(oidx)\n    del oidx\n    gc.collect()\n    tsdf.reset_index(drop = True, inplace = True)\n    retsdf = tsdf.reindex(index=last)\n    retsdf.reset_index(drop = True, inplace = True)\n    delta_tsdf = tsdf - retsdf\n    delta_tsdf[delta_tsdf < 0] = -1\n    del tsdf\n    del retsdf\n    gc.collect()\n    delta_tsdf = pd.DataFrame(delta_tsdf, dtype = np.int64)\n    delta_tsdf.rename(columns = {'timestamp': 'ts_delta'}, inplace = True)\n    retsdf = delta_tsdf\n    while delta_tsdf[delta_tsdf == 0].notna().max()['ts_delta']:\n        retsdf = retsdf.reindex(index=last)\n        retsdf.reset_index(drop = True, inplace = True)\n        delta_tsdf[delta_tsdf == 0] = retsdf[delta_tsdf == 0]\n    delta_tsdf.to_feather('ts_delta.feather')\n    return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ordered_encode_python(values, uniques=None, encode=False):\n    # only used in _encode below, see docstring there for details\n    if uniques is None:\n        uniques = list(dict.fromkeys(values))\n        uniques = np.array(uniques, dtype=values.dtype)\n    if encode:\n        table = {val: i for i, val in enumerate(uniques)}\n        try:\n            encoded = np.array([table[v] for v in values])\n        except KeyError as e:\n            raise ValueError(\"y contains previously unseen labels: %s\"\n                             % str(e))\n        return uniques, encoded\n    else:\n        return uniques","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils.validation import column_or_1d\n\nclass OrderedLabelEncoder(LabelEncoder):\n    def fit(self, y):\n        y = column_or_1d(y, warn=True)\n        self.classes_ = ordered_encode_python(y)\n    def fit_transform(self, y):\n        y = column_or_1d(y, warn=True)\n        self.classes_, y = ordered_encode_python(y, encode=True)\n        return y ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf = tdf[tdf.content_type_id == 0].reset_index(drop = True)\nqdf = pd.read_csv('../input/riiid-test-answer-prediction/questions.csv', dtype = QUESTION_DTYPES)\ntdf = pd.merge(tdf, qdf[['question_id', 'part']], left_on = 'content_id', right_on = 'question_id', how = 'left')\ndel qdf\ntdf.drop(['question_id'], axis = 1, inplace = True)\ngc.collect()\nqdf = pd.read_feather('../input/feather-data/questions_processed.feather')\nqdf.question_id = qdf.question_id - 1\nqdf['num_tag'] = qdf[qdf[['t1','t2','t3','t4','t5','t6']] > 1].T.count()\ntdf = pd.merge(tdf, qdf[['question_id', 't1', 'num_tag']], left_on = 'content_id', right_on = 'question_id', how = 'left')\ndel qdf\ntdf.drop(['row_id', 'content_type_id', 'user_answer', 'question_id'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"users = np.unique(tdf['user_id'])\nquestions = np.unique(tdf['content_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_ratings = []\nfor user in users:\n    rating_object = Rating()\n    user_ratings.append(rating_object)\n\nquestion_ratings = []\nfor question in questions:\n    rating_object= Rating()\n    question_ratings.append(rating_object)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_dict = dict(zip(users, user_ratings))\nquestion_dict= dict(zip(questions, question_ratings))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answers = tdf['answered_correctly'].values\ntemp_user = tdf['user_id'].values\ntemp_question = tdf['content_id'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def win_probability(team1, team2):\n    delta_mu = team1.mu - team2.mu\n    sum_sigma = sum([team1.sigma ** 2, team2.sigma ** 2])\n    size = 2\n    denom = math.sqrt(size * (0.05 * 0.05) + sum_sigma)\n    ts = trueskill.global_env()\n    return ts.cdf(delta_mu / denom)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nwinning_prob = []\nfor user_id, content_id, answer in zip(temp_user, temp_question, answers):\n    count += 1\n    prev_user_rating = user_dict[user_id]\n    prev_question_rating = question_dict[content_id]\n    prob = win_probability(prev_user_rating, prev_question_rating)\n    winning_prob.append(prob)\n    if answer == 1:\n        new_user_rating, new_question_rating = rate_1vs1(prev_user_rating, prev_question_rating)\n    if answer == 0:\n        new_question_rating, new_user_rating = rate_1vs1(prev_question_rating, prev_user_rating)\n    user_dict[user_id] = new_user_rating\n    question_dict[content_id] = new_question_rating\n    if count % 1000000 == 0:\n        print(\"10^6 done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf[\"trueskill_probaility\"]= winning_prob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#orginal\ntdf.t1.fillna(0, inplace = True)\ntdf.fillna(-1, inplace = True)\ntdf.t1 = tdf.t1.astype(np.uint8)\ntdf.prior_question_had_explanation = tdf.prior_question_had_explanation.astype(np.int8)\ntdf.prior_question_elapsed_time = (tdf.prior_question_elapsed_time/1000).astype(np.int16)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf.num_tag = tdf.num_tag.astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf['u_attempt_c'] = (tdf.groupby(['user_id', 'content_id']).cumcount()).astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qdf = pd.read_feather('../input/riiid-data-processing4/questions_processed.feather')\nqdf.question_id = qdf.question_id - 1\ntdf = pd.merge(tdf, qdf[['question_id', 'bundle_id']], left_on = 'content_id', right_on = 'question_id', how = 'left')\ndel qdf\ntdf.drop(['question_id'], axis = 1, inplace = True)\ngc.collect()\ntdf.bundle_id = tdf.bundle_id.astype(np.int16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adf = tdf.groupby('user_id')\nu_dict = adf.groups\ndel adf\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_delta_df = read_feather(\"../input/feather-data/ts_delta.feather\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf = pd.concat([ts_delta_df, tdf], axis = 1)\ndel ts_delta_df\ntdf['ts_delta'] = (tdf['ts_delta']//1000).astype(np.int32)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf['total_explained'] = tdf['prior_question_had_explanation']\ntdf['task_container_id_sorted'] = tdf['task_container_id']\ntdf['10_recent_correctness'] = (tdf['answered_correctly']).astype(np.float16)\ntdf['10_recent_mean_gap'] = tdf['ts_delta']\ntdf['10_recent_mean_gap'][tdf['10_recent_mean_gap'] == -1] = 0\ntdf['mean_elapsed'] = tdf['prior_question_elapsed_time']\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for uid in tqdm(u_dict):\n    task_enc = OrderedLabelEncoder()\n    begin = u_dict[uid][0]\n    end = u_dict[uid][-1] + 1\n    tdf['10_recent_correctness'][begin:end] = (tdf['10_recent_correctness'][begin:end].rolling(window=11,min_periods=0).sum() - tdf['10_recent_correctness'][begin:end])/(tdf['10_recent_correctness'][begin:end].rolling(window=11,min_periods=0).count() - 1)\n    tdf['10_recent_mean_gap'][begin:end] = (tdf['10_recent_mean_gap'][begin:end].rolling(window=10,min_periods=0).mean())\n    tdf['total_explained'][begin:end] = tdf.total_explained[begin:end].cumsum() + 1\n    tdf['task_container_id_sorted'][begin:end] = task_enc.fit_transform(tdf.task_container_id_sorted[begin:end])\n    tdf['mean_elapsed'][begin:end] = (tdf['mean_elapsed'][begin:end].cumsum()/(tdf.task_container_id_sorted[begin:end]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf['total_explained'].fillna(0, inplace = True)\ntdf['total_explained'] = tdf['total_explained'].astype(np.int16)\ntdf['10_recent_mean_gap'].fillna(0, inplace = True)\ntdf['10_recent_mean_gap'] = tdf['10_recent_mean_gap'].astype(np.float32)\ntdf['10_recent_correctness'].fillna(0, inplace = True)\ntdf['10_recent_correctness'] = tdf['10_recent_correctness'].astype(np.float32)\ntdf['mean_elapsed'].fillna(0, inplace = True)\ntdf['mean_elapsed'] = tdf['mean_elapsed'].astype(np.int16)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf['mean_gap'] = tdf.timestamp/tdf.task_container_id_sorted\ntdf['mean_gap'] = tdf['mean_gap'].replace([np.inf, -np.inf], np.nan)\ntdf['mean_gap'].fillna(0, inplace = True)\ntdf.mean_gap = (tdf.mean_gap/1000).astype(np.uint32)\ntdf.drop(['task_container_id_sorted'], axis = 1, inplace = True)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf['abs_time'] = (round(tdf.user_id / 50 + tdf.timestamp / 1000)).astype(np.int32)\ntdf.drop(['timestamp'], axis = 1, inplace = True)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf.sort_values(['abs_time', 'user_id'], inplace = True, ignore_index=True)\ntdf.drop(['abs_time'], axis = 1, inplace = True)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bet_df = read_feather('../input/feather-data/bundle_elapsed_time_mean.feather')\ntdf = pd.concat([tdf, bet_df], axis = 1)\ndel bet_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf1 = tdf[:25000000]\ntdf2 = tdf[25000000:50000000]\ntdf3 = tdf[50000000:75000000]\ntdf4 = tdf[75000000:]\ndel tdf\ngc.collect()\ntdf2.reset_index(drop = True, inplace = True)\ntdf3.reset_index(drop = True, inplace = True)\ntdf4.reset_index(drop = True, inplace = True)\ntdf1.to_feather('trainlgb_prep_1.feather')\ntdf2.to_feather('trainlgb_prep_2.feather')\ntdf3.to_feather('trainlgb_prep_3.feather')\ntdf4.to_feather('trainlgb_prep_4.feather')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}