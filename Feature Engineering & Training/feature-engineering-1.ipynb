{"cells":[{"metadata":{},"cell_type":"markdown","source":"# *DATA PREPARATION*"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport time\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport gc\nimport random\nfrom pickle import dump, load\nfrom trueskill import Rating, quality_1vs1, rate_1vs1\nimport math\nimport trueskill\npd.options.mode.chained_assignment = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DTYPES = {\n    'row_id': np.uint64,\n    'timestamp': np.int64,\n    'user_id': np.uint64,\n    'content_id': np.uint16,\n    'content_type_id': np.int8,\n    'task_container_id': np.uint16,\n    'user_answer': np.int8,\n    'answered_correctly': np.int8,\n    'prior_question_elapsed_time': np.float32,\n    'prior_question_had_explanation': 'boolean'\n}\n\nQUESTION_DTYPES = {\n    'question_id': np.uint16,\n    'bundle_id': np.uint16,\n    'correct_answer': np.int8,\n    'part': np.int8,\n    'tags': str\n}\n\nLECTURE_DTYPES = {\n    'lecture_id': np.uint16,\n    'tag': np.uint16,\n    'part': np.int8,\n    'type_of':str\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_csv(file_name = \"train.csv\", dtype = None, skiprows = None, nrows = None, usecols = None):\n    data = pd.read_csv(file_name, dtype=dtype, skiprows = skiprows, nrows = nrows, low_memory = True, header = 0, usecols = usecols)\n    return data\n\ndef read_feather(file_name = \"../input/feather-data/train.feather\"):\n    data = pd.read_feather(file_name)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Get ts_delta of train.csv, save to feather\ndef get_ts_delta():\n    df = read_feather()\n    df = df[df['content_type_id'] == 0]\n    tsdf = df['timestamp'].astype(np.int64)\n    del df\n    oidx = list(range(tsdf.shape[0]))\n    last = [oidx[-1]]\n    oidx = oidx[:-1]\n    last.extend(oidx)\n    del oidx\n    gc.collect()\n    tsdf.reset_index(drop = True, inplace = True)\n    retsdf = tsdf.reindex(index=last)\n    retsdf.reset_index(drop = True, inplace = True)\n    delta_tsdf = tsdf - retsdf\n    delta_tsdf[delta_tsdf < 0] = -1\n    del tsdf\n    del retsdf\n    gc.collect()\n    delta_tsdf = pd.DataFrame(delta_tsdf, dtype = np.int64)\n    delta_tsdf.rename(columns = {'timestamp': 'ts_delta'}, inplace = True)\n    retsdf = delta_tsdf\n    while delta_tsdf[delta_tsdf == 0].notna().max()['ts_delta']:\n        retsdf = retsdf.reindex(index=last)\n        retsdf.reset_index(drop = True, inplace = True)\n        delta_tsdf[delta_tsdf == 0] = retsdf[delta_tsdf == 0]\n    delta_tsdf.to_feather('ts_delta.feather')\n    return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ordered_encode_python(values, uniques=None, encode=False):\n    # only used in _encode below, see docstring there for details\n    if uniques is None:\n        uniques = list(dict.fromkeys(values))\n        uniques = np.array(uniques, dtype=values.dtype)\n    if encode:\n        table = {val: i for i, val in enumerate(uniques)}\n        try:\n            encoded = np.array([table[v] for v in values])\n        except KeyError as e:\n            raise ValueError(\"y contains previously unseen labels: %s\"\n                             % str(e))\n        return uniques, encoded\n    else:\n        return uniques","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils.validation import column_or_1d\n\nclass OrderedLabelEncoder(LabelEncoder):\n    def fit(self, y):\n        y = column_or_1d(y, warn=True)\n        self.classes_ = ordered_encode_python(y)\n    def fit_transform(self, y):\n        y = column_or_1d(y, warn=True)\n        self.classes_, y = ordered_encode_python(y, encode=True)\n        return y ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf = tdf[tdf.content_type_id == 0].reset_index(drop = True)\nqdf = pd.read_csv('../input/riiid-test-answer-prediction/questions.csv', dtype = QUESTION_DTYPES)\ntdf = pd.merge(tdf, qdf[['question_id', 'part']], left_on = 'content_id', right_on = 'question_id', how = 'left')\ndel qdf\ntdf.drop(['question_id'], axis = 1, inplace = True)\ngc.collect()\nqdf = pd.read_feather('../input/feather-data/questions_processed.feather')\nqdf.question_id = qdf.question_id - 1\nqdf['num_tag'] = qdf[qdf[['t1','t2','t3','t4','t5','t6']] > 1].T.count()\ntdf = pd.merge(tdf, qdf[['question_id', 't1', 'num_tag']], left_on = 'content_id', right_on = 'question_id', how = 'left')\ndel qdf\ntdf.drop(['row_id', 'content_type_id', 'user_answer', 'question_id'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"users = np.unique(tdf['user_id'])\nquestions = np.unique(tdf['content_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_ratings = []\nfor user in users:\n    rating_object = Rating()\n    user_ratings.append(rating_object)\n\nquestion_ratings = []\nfor question in questions:\n    rating_object= Rating()\n    question_ratings.append(rating_object)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_dict = dict(zip(users, user_ratings))\nquestion_dict= dict(zip(questions, question_ratings))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answers = tdf['answered_correctly'].values\ntemp_user = tdf['user_id'].values\ntemp_question = tdf['content_id'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def win_probability(team1, team2):\n    delta_mu = team1.mu - team2.mu\n    sum_sigma = sum([team1.sigma ** 2, team2.sigma ** 2])\n    size = 2\n    denom = math.sqrt(size * (0.05 * 0.05) + sum_sigma)\n    ts = trueskill.global_env()\n    return ts.cdf(delta_mu / denom)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nwinning_prob = []\nfor user_id, content_id, answer in zip(temp_user, temp_question, answers):\n    count += 1\n    prev_user_rating = user_dict[user_id]\n    prev_question_rating = question_dict[content_id]\n    prob = win_probability(prev_user_rating, prev_question_rating)\n    winning_prob.append(prob)\n    if answer == 1:\n        new_user_rating, new_question_rating = rate_1vs1(prev_user_rating, prev_question_rating)\n    if answer == 0:\n        new_question_rating, new_user_rating = rate_1vs1(prev_question_rating, prev_user_rating)\n    user_dict[user_id] = new_user_rating\n    question_dict[content_id] = new_question_rating\n    if count % 1000000 == 0:\n        print(\"10^6 done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf[\"trueskill_probaility\"]= winning_prob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#orginal\ntdf.t1.fillna(0, inplace = True)\ntdf.fillna(-1, inplace = True)\ntdf.t1 = tdf.t1.astype(np.uint8)\ntdf.prior_question_had_explanation = tdf.prior_question_had_explanation.astype(np.int8)\ntdf.prior_question_elapsed_time = (tdf.prior_question_elapsed_time/1000).astype(np.int16)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf.num_tag = tdf.num_tag.astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf['u_attempt_c'] = (tdf.groupby(['user_id', 'content_id']).cumcount()).astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qdf = pd.read_feather('../input/riiid-data-processing4/questions_processed.feather')\nqdf.question_id = qdf.question_id - 1\ntdf = pd.merge(tdf, qdf[['question_id', 'bundle_id']], left_on = 'content_id', right_on = 'question_id', how = 'left')\ndel qdf\ntdf.drop(['question_id'], axis = 1, inplace = True)\ngc.collect()\ntdf.bundle_id = tdf.bundle_id.astype(np.int16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adf = tdf.groupby('user_id')\nu_dict = adf.groups\ndel adf\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_delta_df = read_feather(\"../input/feather-data/ts_delta.feather\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf = pd.concat([ts_delta_df, tdf], axis = 1)\ndel ts_delta_df\ntdf['ts_delta'] = (tdf['ts_delta']//1000).astype(np.int32)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf['total_explained'] = tdf['prior_question_had_explanation']\ntdf['task_container_id_sorted'] = tdf['task_container_id']\ntdf['10_recent_correctness'] = (tdf['answered_correctly']).astype(np.float16)\ntdf['10_recent_mean_gap'] = tdf['ts_delta']\ntdf['10_recent_mean_gap'][tdf['10_recent_mean_gap'] == -1] = 0\ntdf['mean_elapsed'] = tdf['prior_question_elapsed_time']\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for uid in tqdm(u_dict):\n    task_enc = OrderedLabelEncoder()\n    begin = u_dict[uid][0]\n    end = u_dict[uid][-1] + 1\n    tdf['10_recent_correctness'][begin:end] = (tdf['10_recent_correctness'][begin:end].rolling(window=11,min_periods=0).sum() - tdf['10_recent_correctness'][begin:end])/(tdf['10_recent_correctness'][begin:end].rolling(window=11,min_periods=0).count() - 1)\n    tdf['10_recent_mean_gap'][begin:end] = (tdf['10_recent_mean_gap'][begin:end].rolling(window=10,min_periods=0).mean())\n    tdf['total_explained'][begin:end] = tdf.total_explained[begin:end].cumsum() + 1\n    tdf['task_container_id_sorted'][begin:end] = task_enc.fit_transform(tdf.task_container_id_sorted[begin:end])\n    tdf['mean_elapsed'][begin:end] = (tdf['mean_elapsed'][begin:end].cumsum()/(tdf.task_container_id_sorted[begin:end]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf['total_explained'].fillna(0, inplace = True)\ntdf['total_explained'] = tdf['total_explained'].astype(np.int16)\ntdf['10_recent_mean_gap'].fillna(0, inplace = True)\ntdf['10_recent_mean_gap'] = tdf['10_recent_mean_gap'].astype(np.float32)\ntdf['10_recent_correctness'].fillna(0, inplace = True)\ntdf['10_recent_correctness'] = tdf['10_recent_correctness'].astype(np.float32)\ntdf['mean_elapsed'].fillna(0, inplace = True)\ntdf['mean_elapsed'] = tdf['mean_elapsed'].astype(np.int16)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf['mean_gap'] = tdf.timestamp/tdf.task_container_id_sorted\ntdf['mean_gap'] = tdf['mean_gap'].replace([np.inf, -np.inf], np.nan)\ntdf['mean_gap'].fillna(0, inplace = True)\ntdf.mean_gap = (tdf.mean_gap/1000).astype(np.uint32)\ntdf.drop(['task_container_id_sorted'], axis = 1, inplace = True)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf['abs_time'] = (round(tdf.user_id / 50 + tdf.timestamp / 1000)).astype(np.int32)\ntdf.drop(['timestamp'], axis = 1, inplace = True)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf.sort_values(['abs_time', 'user_id'], inplace = True, ignore_index=True)\ntdf.drop(['abs_time'], axis = 1, inplace = True)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bet_df = read_feather('../input/feather-data/bundle_elapsed_time_mean.feather')\ntdf = pd.concat([tdf, bet_df], axis = 1)\ndel bet_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf1 = tdf[:25000000]\ntdf2 = tdf[25000000:50000000]\ntdf3 = tdf[50000000:75000000]\ntdf4 = tdf[75000000:]\ndel tdf\ngc.collect()\ntdf2.reset_index(drop = True, inplace = True)\ntdf3.reset_index(drop = True, inplace = True)\ntdf4.reset_index(drop = True, inplace = True)\ntdf1.to_feather('trainlgb_prep_1.feather')\ntdf2.to_feather('trainlgb_prep_2.feather')\ntdf3.to_feather('trainlgb_prep_3.feather')\ntdf4.to_feather('trainlgb_prep_4.feather')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}